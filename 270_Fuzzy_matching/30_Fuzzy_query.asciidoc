[[fuzzy-query]]
=== 模糊查询

{ref}/query-dsl-fuzzy-query.html[`fuzzy` 查询]是((("typoes and misspellings", "fuzzy query")))((("fuzzy queries"))) `term` 查询的模糊等价。
也许你很少直接使用它，但是理解它是如何工作的，可以帮助你在更高级别的 `match` 查询中使用模糊性。

为了解它是如何运作的，我们首先索引一些文档：

[source,json]
-----------------------------------
POST /my_index/my_type/_bulk
{ "index": { "_id": 1 }}
{ "text": "Surprise me!"}
{ "index": { "_id": 2 }}
{ "text": "That was surprising."}
{ "index": { "_id": 3 }}
{ "text": "I wasn't surprised."}
-----------------------------------

现在我们可以为词 `surprize` 运行一个 `fuzzy` 查询：

[source,json]
-----------------------------------
GET /my_index/my_type/_search
{
  "query": {
    "fuzzy": {
      "text": "surprize"
    }
  }
}
-----------------------------------

`fuzzy` 查询是一个词项级别的查询，所以它不做任何分析。它通过某个词项以及指定的 `fuzziness` 查找到词典中所有的词项。
`fuzziness` 默认设置为 `AUTO` 。

在我们的例子中， `surprise` 比较 `surprise` 和 `surprised` 都在编辑距离 2 以内，
所以文档 1 和 3 匹配。通过以下查询，我们可以减少匹配度到仅匹配 `surprise` ：

[source,json]
-----------------------------------
GET /my_index/my_type/_search
{
  "query": {
    "fuzzy": {
      "text": {
        "value": "surprize",
        "fuzziness": 1
      }
    }
  }
}
-----------------------------------

==== 提高性能


`fuzzy` 查询的工作原理是给定原始词项及构造一个 _编辑自动机_&#x2014;((("fuzzy queries", "improving performance")))((("Levenshtein automation")))
像表示所有原始字符串指定编辑距离的字符串的一个大图表。


然后模糊查询使用这个自动机依次高效遍历词典中的所有词项以确定是否匹配。
一旦收集了词典中存在的所有匹配项，就可以计算匹配文档列表。

当然，根据存储在索引中的数据类型，一个编辑距离 2 的模糊查询能够匹配一个非常大数量的词项同时执行效率会非常糟糕。
下面两个参数可以用来限制对性能的影响：


`prefix_length`::

((("prefix_length parameter")))不能被 ``模糊化'' 的初始字符数。
大部分的拼写错误发生在词的结尾，而不是词的开始。
例如通过将 `prefix_length` 设置为 `3` ，你可能够显著降低匹配的词项数量。

`max_expansions`::

如果一个模糊查询扩展了三个或四个模糊选项，((("max_expansions parameter"))) 这些新的模糊选项也许是有意义的。如
果它产生 1000 个模糊选项，那么就基本没有意义了。
设置 `max_expansions` 用来限制将产生的模糊选项的总数量。模糊查询将收集匹配词项直到达到 `max_expansions` 的限制。
