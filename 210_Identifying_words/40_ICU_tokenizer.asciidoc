[[icu-tokenizer]]
=== icu_分词器


`icu_分词器` 和 `标准分词器` 使用同样的 Unicode 文本分段算法，((("words", "identifying", "using icu_tokenizer")))((("Unicode Text Segmentation algorithm")))((("icu_tokenizer")))
只是为了更好的支持亚洲语，添加了泰语、老挝语、中文、日文、和韩文基于词典的词汇识别方法，并且可以使用自定义规则将缅甸语和柬埔寨语文本拆分成音节。


例如，分别比较((("standard tokenizer", "icu_tokenizer versus"))) `标准分词器` 和 `icu_分词器` 在分词泰语中的 `'Hello. I am from Bangkok.'` 产生的词汇单元：

[source,js]
--------------------------------------------------
GET /_analyze?tokenizer=standard
สวัสดี ผมมาจากกรุงเทพฯ
--------------------------------------------------



`标准分词器` 产生了两个词汇单元，每个句子一个： `สวัสดี` ， `ผมมาจากกรุงเทพฯ` 。这个只是你想搜索整个句子 `'I am from Bangkok.'` 的时候有用，但是如果你仅想搜索 `'Bangkok.'` 则不行。

[source,js]
--------------------------------------------------
GET /_analyze?tokenizer=icu_tokenizer
สวัสดี ผมมาจากกรุงเทพฯ
--------------------------------------------------


相反， `icu_分词器` 可以把文本分成独立的单词（ `สวัสดี` ， `ผม` ， `มา` ， `จาก` ， `กรุงเทพฯ` ），这使得文档更容易被搜索到。


相较而言, `标准分词器` 分词中文和日文的时候“过度分词”了，经常将一个完整的词拆分为独立的字符，因为单词之间并没有空格，很难区分连续的字符是间隔的单词还是一个句子中的单字：

* 向的意思是 _facing_ （面对）， 日的意思是 _sun_ （太阳），葵的意思是 _hollyhock_ （蜀葵）。当写在一起的时候, 向日葵的意思是 _sunflower_ （向日葵）。

* 五的意思是 _five_ （五）或者  _fifth_ （第五）， 月的意思是 _month_ （月份），雨的意思是 _rain_ （下雨）。
  第一个和第二个字符写在一起成了五月，意思是 _the month of May_（一年中的五月）， 然而添加上第三个字符, 五月雨的意思是
  _continuous rain_ （连续不断的下雨,梅雨）。当在合并第四个字符， 式，
  意思是 _style_ （样式），五月雨式这个单词则成了一种不屈不挠持续不断的东西的形容词。


虽然每个字符本身可以是一个单词，但使词汇单元保持更大的原始概念比使其仅作为一个词组的一部分要有意义的多：

[source,js]
--------------------------------------------------
GET /_analyze?tokenizer=standard
向日葵

GET /_analyze?tokenizer=icu_tokenizer
向日葵
--------------------------------------------------



`标准分词器` 在前面的例子中将每个字符输出为单独的词汇单元： `向` ， `日` ， `葵` 。 `icu_分词器` 会输出单个词汇单元 `向日葵` （sunflower） 。



`标准分词器` 和 `icu_分词器` 的另一个不同的地方是后者会将不同书写方式的字符（例如，`βeta` ）拆分成独立的词汇单元 &#x2014; `β` 和 `eta`&#x2014; ，而前者则会输出单个词汇单元： `βeta` 。
